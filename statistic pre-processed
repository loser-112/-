import numpy as np
import os
import cv2
from glob import glob
from sklearn.model_selection import train_test_split

# 加载图像和掩码
def load_data(image_path, mask_path):
    images = sorted(glob(os.path.join(image_path, "*.png")))
    masks = sorted(glob(os.path.join(mask_path, "*.png")))
    return images, masks

# 示例路径
image_path = "path/to/images"
mask_path = "path/to/masks"

images, masks = load_data(image_path, mask_path)
def preprocess_image(image, target_size):
    image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)
    image = cv2.resize(image, target_size)
    image = image / 255.0  # 标准化
    image = np.expand_dims(image, axis=-1)  # 扩展维度以匹配U-Net输入
    return image

def preprocess_mask(mask, target_size):
    mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)
    mask = cv2.resize(mask, target_size)
    mask = mask / 255.0  # 标准化
    mask = np.expand_dims(mask, axis=-1)  # 扩展维度以匹配U-Net输入
    return mask

# 目标尺寸
target_size = (128, 128)

# 预处理所有图像和掩码
X = [preprocess_image(img, target_size) for img in images]
y = [preprocess_mask(msk, target_size) for msk in masks]

# 转换为NumPy数组
X = np.array(X)
y = np.array(y)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 创建ImageDataGenerator对象
data_gen_args = dict(rotation_range=20,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2,
                     horizontal_flip=True,
                     fill_mode='nearest')
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)

# 适应数据生成器
image_datagen.fit(X, augment=True)
mask_datagen.fit(y, augment=True)

# 创建生成器
seed = 1
image_generator = image_datagen.flow(X, batch_size=32, seed=seed)
mask_generator = mask_datagen.flow(y, batch_size=32, seed=seed)

# 合并图像和掩码生成器
train_generator = zip(image_generator, mask_generator)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
from tensorflow.keras import layers, models

# 使用数据生成器进行训练
model.fit(train_generator, steps_per_epoch=len(X_train) // 32, epochs=50, validation_data=(X_val, y_val))
